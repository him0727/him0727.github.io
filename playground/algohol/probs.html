<html>
<head>
<title>My problems :: Algohol - Him0727 .NET</title>
<meta charset="utf-8">
<meta name="author" content="CHAN TAK HIM, him0727">
<meta name="description" content="Aloghol, a website about data structure and algorithm, powered by HIM0727 .NET" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="favicon.ico" type="image/x-icon" rel="shortcut icon" />
<link rel="stylesheet" href="styles/global.css">
<link rel="stylesheet" href="styles/probs.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-11490216-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-11490216-2');
</script>
</head>
<body>
  <nav class="content">
    <span id="nav-left"></span>
    <span id="nav-right"></span>
  </nav>
  <div class="content" style="background-color: #EFF1FA;">
    <span style="color: #36AD16;">
      <svg class="bi bi-emoji-laughing" style="margin-top: 10px;" width="1em" height="1em" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
        <path fill-rule="evenodd" d="M8 15A7 7 0 1 0 8 1a7 7 0 0 0 0 14zm0 1A8 8 0 1 0 8 0a8 8 0 0 0 0 16z"/>
        <path fill-rule="evenodd" d="M12.331 9.5a1 1 0 0 1 0 1A4.998 4.998 0 0 1 8 13a4.998 4.998 0 0 1-4.33-2.5A1 1 0 0 1 4.535 9h6.93a1 1 0 0 1 .866.5z"/>
        <path d="M7 6.5c0 .828-.448 0-1 0s-1 .828-1 0S5.448 5 6 5s1 .672 1 1.5zm4 0c0 .828-.448 0-1 0s-1 .828-1 0S9.448 5 10 5s1 .672 1 1.5z"/>
      </svg>
       - I am pleased to announce that my problem "LNTILING - Long Tiling" was selected as one of the ten problems in <a href="https://www.bubblecup.org/CompetitorsCorner/Problems" target="_blank">Round 2, Bubble Cup 13 (2020)</a>.
    </span>
  </div>
  <div class="content">
    <div id="left-menu" style="text-align: left">
      <ul>
        <li>ACRYM - Acronym</li>
        <li>KTRANS - K-transfer journey</li>
        <li>MACHCOOL2 - Machine Cooling II</li>
        <li>MACHCOOL - Machine Cooling</li>
        <li>TLPNGEM - Teleporters and Gems</li>
        <li>LNTILING - Long Tiling</li>
        <li>GIFTARNG - Gift Arrangement</li>
        <!--<li>PSHAPE - Plane Shapes Formation</li>-->
        <!--<li>PRIPYAT - Pripyat</li>-->
        <li>TRIBT - Triangle in Binary Tree</li>
        <li>SMTOILET - Smelly Toilets</li>
        <li>MAPEXC - Map Exploration Cost</li>
        <li>TRFPLN - Traffic Planning</li>
      </ul>
    </div>
    <div id="right-content"></div>
    <div style="display: none;">
      <div id="ACRYM">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/ACRYM/" target="_blank">Link</a> | 
          Time: 0.8s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Dynamic Programming</span><span class="tag">Combinatorics</span><span class="tag">String</span><span class="tag">Prefix & Suffix</span><span class="tag">Subsequence</span>
        </div>
        <hr />
        Let's model the problem as a tree: We have a dummy root at depth 0. At depth i, all siblings represet all prefixes of W<sub>i</sub>, and each has C child nodes where C is the number of prefixes of W<sub>i + 1</sub>, which equals |W<sub>i + 1</sub>|. For conjunction and adposition, the empty string is included. From the tree, we get every combination of prefixes of each word. To reduce the number of nodes, check if the current combination matches the corresponding prefix of S. So the solution is to count the number of path reaching any leaf at depth N from the root. But this is inefficient due to duplicate computation, and in the worst case, we have 1 + &Pi;<sub>i=2</sub><sup>N</sup>|W<sub>i</sub>| nodes.
        <h3>Approach 1: Dynamic Programming (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/ACRYM.cpp" target="_blank">Solution Link</a>)</h3>
        To iteratively solve this problem without recursion, let's define f(x) as the number of possible combinations of making S<sub>1 ... x</sub> using the prefixes from W<sub>1</sub> to W<sub>i - 1</sub>. Donate f '(x) as the same target function but using the prefixes from W<sub>1</sub> to W<sub>i</sub>. Obviously, we have to make use of the result of f(x) in order to get f '(x) because the order of words is fixed. For W<sub>1</sub>, f(1) = f(2) = ... = f(k) = 1 where k is the length of longest common prefix with S, otherwise 0. From this observation, we can see that in the initial f(x), the value is either 1 or 0, and all '1's will be on the left side. For W<sub>2</sub>, we will consider all prefixes of the word. For each prefix, we will also consider all prefixes of S. Let P<sub>[W<sub>i</sub>, S]</sub> be the length of current prefix of W<sub>i</sub> or S. Now we have two cases: W<sub>2</sub> is conjunction or adposition, or it is not. If it is, intially f '(x) = f(x) because we can simply skip the word. If not, as the second case, f '(x) = 0 for all x. Now we have to check whether W<sub>2 <sub>1 ... P<sub>W<sub>2</sub></sub></sub></sub> is the suffix of S<sub>P<sub>S</sub> - P<sub>W<sub>2</sub></sub> + 1 ... P<sub>S</sub></sub>. But it only means that W<sub>2</sub> is a valid candidate, it does not mean S<sub>1 ... P<sub>S</sub></sub> is contiguous considering any combination of prefixes of W<sub>1</sub> and W<sub>2</sub>. That is, S<sub>1 ... P<sub>S</sub> - P<sub>W<sub>2</sub></sub></sub> must be the prefix of W<sub>1</sub>. Luckily, f(x) already provides the answer considering W<sub>1</sub> ... W<sub>i - 1</sub> following their order. Let's see the state transition of f '(x):  
        <ul>
          <li>For each word W<sub>i</sub>, where i &gt; 1: <br />
          - f '(x) = f(x), for all x, if W<sub>i</sub> is conjuction or adposition<br />
          - f '(x) = 0, for all x, otherwise
          </li>
          <li>For each value of P<sub>W<sub>i</sub></sub> and each value of P<sub>S</sub>, where 1 &le; P<sub>W<sub>i</sub></sub> &le; min(|W<sub>i</sub>|, |S|) and P<sub>W<sub>i</sub></sub> &lt; P<sub>S</sub> &le; |S|: <br />
          - f '(P<sub>S</sub>) = f '(P<sub>S</sub>) + f(P<sub>S</sub> - P<sub>W<sub>i</sub></sub>), if f(P<sub>S</sub> - P<sub>W<sub>i</sub></sub>) &gt; 0 and W<sub>i <sub>1 ... P<sub>W<sub>i</sub></sub></sub></sub> equals S<sub>P<sub>S</sub> - P<sub>W<sub>i</sub></sub> + 1 ... P<sub>S</sub></sub><br />
          </li>
          <li>Make use of f '(x) to trasfer to the next state: <br />
          - f(x) = f '(x)
          </li>
        </ul>
        By doing the above procedure for W<sub>2</sub> to W<sub>N</sub>, our final answer is f(|S|). There are two optimizations to speed it up: First, we should check whether f(P<sub>S</sub> - P<sub>W<sub>i</sub></sub>) &gt; 0, and then check if P<sub>W<sub>i</sub></sub> is part of S's suffix. This is because substring is O(N) which slowers our algorithm N times. If we know the result is not contiguous, we don't have to check the substring. Second, if f '(x) equals 0 for all x, which means the result is no longer contiguous, we can immediately determine the answer is 0 without trying the remaining words. Everything is bounded by |S|, so the time complexity is O(N * |S|<sup>2</sup>).<br /><br />
        Actually, we can think the problem like that: for each word, it forms a set with |W<sub>i</sub>| elements, containing all prefixes of the word. For conjunction or adposition, we have one more element which is the empty string. The value is their length. Now we have N sets, and a bag with |S| capacity, we want to select one element from each set, such that bag value is exactly |S|. But one more constraint is added: the selected element must be part of the suffix of current S. Therefore, this problem is a variant of multiple-choice knapsack problem.<br /><br />
        By the way, a solver created another harder version of this problem <a href="https://www.spoj.com/problems/ACRYM2/" target="_blank">Acronym II</a>. The story is the same, but with harder constraints: |S| and |W<sub>i</sub>| are longer. It can be solved by a famous string data structure. Welcome to solve!
      </div>
      <div id="KTRANS">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/KTRANS/" target="_blank">Link</a> | 
          Time: 0.4s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Dynamic Programming</span><span class="tag">Shortest Path</span>
        </div>
        <hr />
        We can view the shortest travel time as the shortest weighted path. Then this problem is clearly all-pairs constrained shortest path problem, the true way to go is to use a variant of Floyd-Warshall algorithm.
        <h3>Approach 1: Run Floyd-Warshall algorithm K times (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/KTRANS.cpp" target="_blank">Solution Link</a>)</h3>
        In this problem we have two constraints: the maximum number of edges on a path must not exceed K, and the amount of incoming accumulate flow for each directly connected pair of nodes is restricted. Due to the second constraint, the following shortest path property is not necessarily true: A subpath of a shortest path is a shortest path. Given a directed graph G = (V, E) with weight W for each edge e &isin; E and the second constraint L for each vertex v &isin; V, where V donates cities, E donates flights and W donates travel time. If a shortest path P(u, v) with at most 3 edges passes through (u - v<sub>2</sub> - v<sub>3</sub> - v), P(v<sub>2</sub>, v) can be (v<sub>2</sub> - v), if δ(u, v<sub>2</sub>) &gt; L(v<sub>2</sub>, v) and δ(v<sub>2</sub>, v<sub>3</sub>) + δ(v<sub>3</sub>, v) &gt; δ(v<sub>2</sub>, v). Therefore, the resulting δ(u, v) may not necessarily be δ(u, k) + δ(k, v) for arbitrary k. That is why we should not raise the distance matrix into the power of K using binary exponention in O(log K) and combine the results together. Instead we should find the shortest path by adding one more edge to the current path every time, to make sure that  &sum;<sub>i=1</sub><sup>|P(u, k)|</sup> W(P(u, k)<sub>i - 1</sub>, P(u, k)<sub>i</sub>) does not exceed L(k, v). If it does, find the second best path from k to v.<br /><br />
        We are going to create two distance matrices D<sub>1</sub> and D<sub>2</sub>, D<sub>1</sub> for the results of length of K - 1 and D<sub>2</sub> for the results of length of K. Filling with &infin; for all pairs of vertices and filling 0 with if u = v. Then, we will start finding the shortest path for each (u, v) with length from 1, 2 ... K incrementally  using previous K - 1 results in O(K). In each iteration, by relaxing all the edges (u, v) for each vertex, the computed shortest travel time from current vertex to v is tested whether it can be improved by passing through P(current vertex, u) plus one more edge (u, v), while satisfying the constraint L(u, v). So, during the relaxation process, we iterative over all vertices, considering current vertex n as an intermediate vertex, if D<sub>1</sub>(n, u) &ne; &infin; and D<sub>1</sub>(n, u) &le; L(u, v), D<sub>2</sub>(n, v) = min(D<sub>2</sub>(n, v), D<sub>1</sub>(n, u) + W(u, v)). After K relaxations, we have to swap D<sub>1</sub> and D<sub>2</sub> because we are using the results of length of K - 1 to update the current results of length of K, directly using D<sub>2</sub> as distance matrix breaks both constraints. Finally, since D<sub>1</sub> and D<sub>2</sub> are swapped during the end of each iteration, D<sub>1</sub> is our answer and remember to replace &infin; with -1. Or we can define &infin; as -1, but in this case, we have to modify the condition check: D<sub>2</sub>(n, v) will only be updated when D<sub>2</sub>(n, v) = -1 or D<sub>(n, v)</sub> &gt; D<sub>1</sub>(n, u) + W(u, v), following the order of condition check. The algorithm can be run in O(K * |E| * |V|), which is (|V| - 1) * |V| * (|V| - 1) * |V| = 6002500 iterations in the worse case.
      </div>
      <div id="MACHCOOL2">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/MACHCOOL2/" target="_blank">Link</a> | 
          Time: 0.5s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Graph</span><span class="tag">Greedy</span><span class="tag">Heap</span><span class="tag">Matching</span><span class="tag">Binary Search</span><span class="tag">Depth-first Search</span>
        </div>
        <hr />
        The requirements of this problem are similar to MACHCOOL, except for the duration of tasks and the number of machines. We have many ways to solve this problem.
        <h3>Approach 1: Min heap (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MACHCOOL2_1.cpp" target="_blank">Solution Link</a>)</h3>
        Since a task must wait for the preceding task to complete before it can proceed, we are only interested in the sub task with longest duration for the i-th task which is max(D<sub>i, j</sub>). Let T be pairs of start time and end time of all tasks, equivalent to {START<sub>i</sub>, START<sub>i</sub> + max(DURATION<sub>i, j</sub>)}. First, we sort all pairs in an ascending order. We can divide the problem into two sub problems: Let M be the minimum number of machines we need, find out M and how to distribute them optimally. To answer these two questions, we will make use of a tree data structure called heap, that is, priority queue in C++. We want one machine to deal with as many tasks as possible which forms a greedy insight. Therefore, we must assign T<sub>i</sub> to a machine as early as possible once its start time &ge; the end time of the latest task assigned to that machine. Otherwise, we need a new machine to hold that task. In a min heap, the top element is the smallest one. We are going to put the end time of T<sub>i</sub> into the heap. By looping through the sorted pairs, we are going to see if there is any conflict between T<sub>i</sub> and other previous tasks. If the heap is not empty and the start time of T<sub>i</sub> &ge; the top element of the heap (smallest end time), T<sub>i</sub> can be held by existing machines, so we remove the top element. And of course, put the end time of T<sub>i</sub> into the heap. Finally, the remaining elements of the heap are the end time of tasks which we need a new machine to handle. Hence, M is the heap size.<br /><br />
        To distribute them optimally, refer to the greedy approach mentioned in MACHCOOL, first we consecutively distribute M machines as early as possible by pushing the first M tasks into the empty heap. For the remaining N - M tasks, we want to maximize the gap between the start time of T<sub>i</sub> and the end time of the latest task assigned to any machine. Since the top element is already the earliest end time of the task already assigned, we don't even have to classify which machine explicitly and it is done in O(1). Looping through the remaining tasks, do pop and push in each iteration, the answer is simply min(start time of T<sub>i</sub> - top element of the heap). This can be done in O(N * log N) as well, so the solution's time complexity is also O(N * log N). 
        <h3>Approach 2: Line sweep with binary search (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MACHCOOL2_2.cpp" target="_blank">Solution Link</a>)</h3>
        We are going to binary search on the answer. But before, we need to know the least number of machines needed to handle all tasks. We use the same greedy insight with line sweep algorithm. Donate f(C) as the least number of machines needed to finish all tasks with C cooling time for each machine. This time, we don't store tasks' start time and end time in pairs, instead we store the start time and end time discretely with a type to identity it's start time or end time. Hence, |T| will be 2 * N. In the fucntion, we loop through all the tasks and add both (START<sub>i</sub>, 1) and (START<sub>i</sub> + max(DURATION<sub>i, j</sub>) + C, -1) into T, where 1 tells us it's start time and -1 tells it's end time. After sorting, every task's start time and end time are decoupled and placed on a timeline. Now we loop through T and by identifying the type of T<sub>i</sub>, we know if the type is 1 we have a new task so a machine is needed. Otherwise, we just finished an old task, so a machine is free. Therefore, the type is like a counter, it either increases or decreases by 1. Initially the counter is 0, we keep adding the type of T<sub>i</sub> to that counter during each iteration, and lastly f(C) = max(counter<sub>i</sub>). Let M be the least number of machines required, since the minimum cooling time is 0, so M = f(0).<br /><br />
        Again, let L and R be the lower bound and upper bound of the search range, where L = 0 and R = 86400. During each search, we find the median MID of L and R, treating MID as the cooling time. Therefore, we will check whether M &ge; f(MID). If so, MID is a valid answer because M machines are enough to handle all the tasks with MID cooling time, and we just set L to MID + 1 to search a larger answer. Otherwise, we need to decrease the cooling time hence R = MID - 1. During each search, we invoke f(MID) and it requires sorting, so this approach is run in O(N * log N * log 86401) = O(N * log N).
        <h3>Approach 3: Maximum bipartite matching (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MACHCOOL2_3.cpp" target="_blank">Solution Link</a>)</h3>
        This problem can be modelled as a graph problem. Let G = (V, E) be a directed acyclic graph (DAG), where V are tasks and there is an edge E from V<sub>1</sub> to V<sub>2</sub> if and only if END<sub>V<sub>1</sub></sub> &le; START<sub>V<sub>2</sub></sub>. From the DAG, every node on any path can be distributed to a machine. There may be many valid paths, if we want to find the minimum number of machines we need, we have to minimize the number of paths so that every node appears only once. That is, we want to maximize the ordered pair (u, v) where there is an edge from u to v and both cannot not be the first and second element more than once. This is equivalent to the minimum edge cover problem in a bipartite graph. Let L and R be two disjoint and independent sets, both include V in G, in other words, the number of tasks. Edges connecting from L to R are corresponding to E in G as well. This will form a bipartite graph. Finding the maximum matching in bipartite graph is a well known problem which can be done in O(|V|<sup>3</sup>) where |V| equals N which is the number of tasks, by using Hungarian algorithm with depth-first search. Obviously, the number of unmatched points (Maximum independent set) in L is the number of machines we need. Once we know the maximum matching, we can also get the minimum number of machines we need because maximum independent set = minimum edge cover = |V| - maximum matching in bipartite graph. Now, let M be the minimum number of machines.<br /><br />
        To get the maximum cooling time, we are going to do binary search. There is an edge E from V<sub>1</sub> to V<sub>2</sub> if and only if END<sub>V<sub>1</sub></sub> + some cooling time &le; START<sub>V<sub>2</sub></sub>=. It is too slow to try every possible value. We know that the cooling time affects how G looks like. If it is larger, |E| and matchings become less, hence the number of machines increases, vice versa. Again, the search bound is from 0 to 86400, and our target is to let the median MID = M. During each check, we construct G and draw an edge from u to v if and only if u + MID &le; v. Actually, we don't have to construct the graph explicitly, instead we can let MID be a global variable or pass it by reference, and change the condition check in depth-first search (DFS). The next step is just to find out the minimum edge cover in O(N<sup>3</sup>). We want the upper bound since we need to maximize the cooling time, if current matchings = M, we have to increase MID to make the result larger. If M &lt; current matchings, we want less |E| and matchings to make the result less. The whole problem can be solved in O(N<sup>3</sup> * log 86401).
      </div>
      <div id="MACHCOOL">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/MACHCOOL/" target="_blank">Link</a> | 
          Time: 0.3s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Greedy</span><span class="tag">Binary Search</span><span class="tag">Ad-hoc</span>
        </div>
        <hr />
        This problem seems complicated because there are many ways to distribute machines optimally, but there is a straightforward solution with greedy insight.
        <h3>Approach 1: Always choose i + M machine (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MACHCOOL_1.cpp" target="_blank">Solution Link</a>)</h3>
        Let's sort the tasks T by the start time in an ascending order. To optimize the distribution of M machines, we should not put the same machine on consecutive tasks. Consider this intuition: Let T = {T<sub>1</sub>, T<sub>2</sub>, T<sub>3</sub>} and M = 2. If we assign the first machine to {T<sub>1</sub>, T<sub>2</sub>}, the second the machine to {T<sub>3</sub>}, this answer is then T<sub>2</sub> - T<sub>1</sub>. If only {T<sub>2</sub>} is assigned to the second machine, the answer is T<sub>3</sub> - T<sub>1</sub>. Note that the tasks are sorted by the start time, so T<sub>3</sub> &ge; T<sub>2</sub> &ge; T<sub>1</sub>. We add one more task T<sub>4</sub>, obviously min(T<sub>3</sub> - T<sub>1</sub>, T<sub>4</sub> - T<sub>2</sub>) &ge; min(T<sub>2</sub> - T<sub>1</sub>, T<sub>4</sub> - T<sub>3</sub>). This is also true for arbitrary N where N > 0. From the example, we know that the best approach to make the number of tasks assigned to each machine and its interval evenly distributed. It helps avoid the result from being pulled down by the especially small interval of some other machines. That's why we better assign the i-th task to the i modulo M machine individually. To implement that, we can simply loop through T and min(86400, T<sub>i + M</sub> - T<sub>i</sub>), where i + M ≤ N, will be our answer. Due to sorting, we reach the solution in O(N * log N).
        <h3>Approach 2: Binary search (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MACHCOOL_2.cpp" target="_blank">Solution Link</a>)</h3>
        This idea is still the same as before, but we are going to binary search on the answer. Again, we sort T first. Let L and R be the lower bound and upper bound of our search range, where L = 0 and R = 86400. During each search, we find the median MID of L and R, loop through T to see whether T<sub>i + M</sub> - T<sub>i</sub> &ge; MID. If so, it means the maximum cooling time is greater than or equal to MID, so we can assume MID is our answer and set L to MID + 1 to search a larger answer. Otherwise, MID is not a valid answer so we have to reduce the upper bound by setting R = MID - 1. The time complexity of this approach is still (N * log N). Doing this is complicated than directly computing the answer, though their running times are very close even if this approach has extra log 86401 * N steps.
      </div>
      <div id="TLPNGEM">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/TLPNGEM/" target="_blank">Link</a> | 
          Time: 0.6s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Dynamic Programming</span><span class="tag">Queue</span><span class="tag">Stack</span>
        </div>
        <hr />
        This problem can be solved by dynamic programming with greedy insight in O(N). Since we can only move right, we have to collect all the gems sequentially.
        <h3>Approach 1: Dynamic programming (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/TLPNGEM.cpp" target="_blank">Solution Link</a>)</h3>
        Let T and G be the positions of teleporters and gems, respectively. We define two variables TI and GI to point to their current indices, where 1 &le; TI &le; |T| and 1 &le; GI &le; |G|. The maximum number of move is G<sub>|G|</sub> if |T| &le; 1 as we can only move one unit each time. For the minimum number of moves, it depends |T| and their positions and G<sub>|G|</sub>, but we definitely want to make use of the optimal results in last unit or previous 3 teleporters. Donate f(p) as the minimum number of moves from position 1 to p of S, where 1 &le; p &le; G<sub>|G|</sub>. Obviously, initially p(1) = 0 and for p &gt; 1, f(p) = f(p - 1) + 1. Hence, f(p) = p - 1. This is because we are already at position 1 and as mentioned before, the worse case is to move one unit each time. Let's start at position 1 and move right one unit at a time. For each position, our first step is to check if S<sub>p</sub> belongs to "@" (teleporter) or "*" (gem).
        <ul>
          <li>S<sub>p</sub> = "*", we simply collect the gem and increase GI by 1.</li>
          <li>S<sub>p</sub> = "@", we have to update the minimum number of moves to reach the next 3 teleporters. We define i as the answer for f(T<sub>TI + i</sub>) we want to update, where 1 &le; i &le; 3. For each i, if TI + i &le; |T|, for f(T<sub>TI + i</sub>) we may consider either being transferred from the current teleporter T<sub>TI</sub> or not begin transferred. Hence, f(T<sub>TI + i</sub>) = min(f(T<sub>TI + i</sub>), f(p) + 3). Lastly, don't forget to increase TI by 1.</li>
        </ul>
        Finally, the answer is f(G<sub>|G|</sub>). There are two implementations using the same idea, which are done by double-ended queue (Deque) and three pointers. For three pointers, the number of code lines is much shorter, but it cannot handle arbitrary number of how many teleporters we are allowed to reach from the current one, while our approach does. However, it still looks elegant.
      </div>
      <div id="LNTILING">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/LNTILING/" target="_blank">Link</a> | 
          Time: 0.7s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><br />
          <span class="tag">Dynamic Programming</span><span class="tag">Depth-first Search</span><span class="tag">Bitmasking</span><span class="tag">Simulation</span><span class="tag">Implementation</span>
        </div>
        <hr />
        One strategy to solve the problem is to try all possibilities in O(2<sup>N</sup> * N!), which is insufficient and will exceed the time limit. There is no polynomial time algorithm to solve this problem, but we can use some techniques to speed up the solution.
        <h3>Approach 1: Depth first search with bitmasking and memoization (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/LNTILING.cpp" target="_blank">Solution Link</a>)</h3>
        Let's us simulate putting different tiles T<sub>i</sub> into the gap G. We have to answer two questions: whether T<sub>i</sub> can fit in G at position P, and what is the proper subset of available tiles and its permutation to fit in the whole G?<br /><br />
        To answer the first question, we define g(P, T) to tell us whether tile T can fit in G at position P, where 1 &le; P &le; |G|. One quick check to determine it cannot fit is that |T| + P - 1 &gt; |G|. Otherwise, every time we can rotate T 90 degrees from its head or tail, so we get 8 different placements in total for each tile. Of course we can try a different placement to see if the whole T fit in G, but it requires a lot of coding and less efficient. Instead of doing that, we can simply compare the turn of i and i + 1 position of T with the turn of P + i - 1 and P + i position of G, where 1 &lt; i &lt; N. Similarly, to check the tile with different placements rotated from the tail of T, we can compare the turn of i and i - 1 position of T with the turn of P + |T| - i - 1 and P + |T| - i, where 2 &lt; i &le; |T|. Note that we ignore the first unit of T and G at P, because it will always fit in G regardless of its rotation. Let LDRU represent T's turn of left, down, right, up, respectively. We also define a map TURN to map LDRU to 0123 respectively. For each turn, it can be rotated by 90 degrees or go straight, so if we minus the turn at i + 1 with i according to the map by formula (MAP<sub>turn at i + 1</sub> - MAP<sub>turn at i</sub> + 4) modulo 4, the result is always either 0 (go straight), 1 (turn left 90 degres) or 3 (turn right 90 degrees). It will never be 2 (turn 180 degrees) because it means two units are overlapped which causes a contradiction. To conclude, we can check from the head of T, and from the current position of G, one unit at a time using the current and previous unit, except the first unit. If the turn of T and the turn of G are both the same, it fits. If it fails, we check reversely from the tail of T to see if it fits.<br /><br />
        As for the second question, the solution is some kind of intelligent brute force. Let's start from brute force, we try all subsets S &sub; T and its permuatations to see if the tiles from S can fit in G. Let's |T| be 3 as an example, there are 2<sup>3</sup> - 1 = 5 subsets excluding the empty set, each has |S<sub>i</sub>|! permutations. To generate all candidates, we can use depth first search to generate all subsets and permutations for S<sub>i</sub> on the fly. To avoid from counting duplicate T, we use bitmasking to remember which tiles are used to save memory. Let's define a funtion f(M, P) to check whether the subset excluded from mask M can fit in G starting at P. For each mask M, let's loop through all 3 available tiles and perform f(M | (1 &lt;&lt; i), P + |T|), if T<sub>i</sub> is not included and T<sub>i</sub> can fit in G at P. Hence, the following conditions must be satisfied: M & (1 &lt;&lt; i) = 0, and g(P, T<sub>i</sub>) = true. This pruning approach means if g(P, T<sub>i</sub>) = false, the current permutation is no longer valid and we stop exploring the remaining tiles, which greatly reduces the number of permutations. Soon we find that this approach exceeds the time limit, because there are so many overlapping subproblems. f(0, 0) checks from T<sub>1</sub>, T<sub>1</sub>T<sub>2</sub>, T<sub>1</sub>T<sub>2</sub>T<sub>3</sub>, T<sub>1</sub>T<sub>3</sub>T<sub>2</sub> ... T<sub>3</sub>T<sub>2</sub>T<sub>1</sub>. From that, the following masks are passed in order: 0 (Intital), 1 3 7 5 7 (from T<sub>1</sub>), 2 3 7 6 7 (from T<sub>2</sub>) and 4 5 7 6 7 (from T<sub>3</sub>). We discover that some masks are duplicate, like 3 and 5, and this situation becomes more obvious with the increase of |T|. To avoid from computing the subproblems again we already solved, let's store the results in an array A using M as index. A has three states: -1 (unsolved), 0 (unfit) and 1 (fit), initially A is filled with -1. In our function, we know that A<sub>M</sub> = 1 when P = |A|, therefore we can determine the value of A<sub>M</sub> based on the base case. If the base case is 1, any mask contributes to that will also have A<sub>M</sub> = 1. Apart from the base case, We can check if A<sub>M</sub> &ne; -1, which means we have computed the result for M already, if so just directly return A<sub>M</sub>. It saves us time from invoking DFS many times. This is called memoization, a kind of dynamic programming using recursion.<br /><br />
        With the help of bitmasking and memoization, plus some pruning, we discard all invalid permutations as early as possible to make the recursion tree shorter. It also saves a lot of time on computation by storing the results of subproblems to speed up the solution.
      </div>
      <div id="GIFTARNG">
        <div class="constraint">
          Problem statement: <a href="https://www.spoj.com/problems/GIFTARNG/" target="_blank">Link</a> | 
          Time: 0.4s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Dynamic Programming</span>
        </div>
        <hr />
        In this problem, we have to consider all possible rotations of box and figure out the optimal combination. Instead of an O(6<sup>N</sup>) naive solution, an O(N) dynamic programming solution will be described here.
        <h3>Approach 1: Dynamic programming (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/GIFTARNG.cpp" target="_blank">Solution Link</a>)</h3>
        Firstly, W, H, D donate weight, height and depth, respectively. Let's start with the three unduplicate surfaces of a gift box {W, D}, {H, D}, {W, H}, considering every possible variants of them, we have 3! = 6 possible rotations {W, D, H}, {W, H, D}, {D, W, H}, {D, H, W}, {H, W, D} and {H, D, W}. Let R<sub>i, j</sub>, where 1 &le; j &le; 6, be the corresponding dimensions of j-th rotation of the i-th gift. We want to maximize the total visible area without keeping trying all combinations repeatedly, so let's define a function f(i, j), where 1 &le; r &le; 6, as the current maximum visible area we can get from 1 to i-th gift, in which we place the i-th gift with R<sub>i, j</sub> dimension. Then, we have the following transition states: 
        <ul>
          <li>f(1, j) = R<sub>1, j</sub>{W, D} * 2 + R<sub>1, j</sub>{H, D} * 2 + R<sub>1, j</sub>{W, H}.<br />
              For the first gift, f(1, j) is simply the total surface area except the bottom of that gift with R<sub>1, j</sub> dimension.</li>
          <li>f(i, j) = max(f(i - 1, j)) + R<sub>i, j</sub>{W, D} * 2 + R<sub>i, j</sub>{W, H} + DD + DH, where i &gt; 1.</li>
              For the i-th gift, we only place this after the most optimal combination from 1 to i - 1 gift so we have to find out max(f(i - 1, j)) which takes 6 times computation. Note that if H and D are both less than previous box's H and D, the total area of {H, D} is not affected. Donate DD and DH as the vertical difference and horizontal area difference of {H<sub>i</sub>, D<sub>i</sub>} and {H<sub>i - 1</sub>, D<sub>i - 1</sub>} respectively. If D<sub>i</sub> &gt; D<sub>i - 1</sub> or H<sub>i</sub> &gt; H<sub>i - 1</sub>, DD or DH is simply the double of the extra area of {H, D}. If D<sub>i</sub> &gt; D<sub>i - 1</sub> and H<sub>i</sub> &gt; H<sub>i - 1</sub>, we have to minus the overlapping area of DD and DH and mulitply the sum of DD and DH by 2 as well. Otherwise, DD = 0 and DH = 0.</li>
        </ul>
        To reduce the space complexity, since we just need f(i - 1, j) to compute f(i, j), there is no need to store all states prior to i - 1. At the end, we will have 6 different answers, representing the maximum of area of 1 to n - 1 th gift plus the n-th gift with R<sub>n, j</sub> dimensions. The answer is then be max(f(r, n)). Except the first gift, the computation for i-th gift takes 36 times to combine f(i - 1, j) and 6 possible rotations, hence O(36 * (N - 1) + 6) for all gift boxes in total. The overall time complexity becomes O(N). 
      </div>
    <!--
    <div id="PSHAPE">
    <div class="constraint">
      Problem statement: <a href="http://www.spoj.com/problems/PSHAPE" target="_blank">Link</a> | 
      Time: 0.2s per test file | 
      Source: 5000B | 
      Memory: 1536MB | 
      Languages: ALL
    </div>
    <hr />
    In this problem, we can pair any X with any Y to form new coordinates. A greedy insight will help form optimal distribution of coordinates and maximize the area of three shapes.
    <h3>Approach 1: Greedy solution (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/PSHAPE.cpp" target="_blank">Solution Link</a>)</h3>
    Before thinking of the optimal distribution of coordinates, we firstly think of the order of the formation of shapes. Since one shape must wrap one shape, circle's area is the largest. The order of formation will be circle &gt; quadrilateral &gt; triangle. By choosing two coordinates {min<sub>x</sub>, min<sub>y</sub>} and {max<sub>x</sub>, max<sub>y</sub>}, we get the farthest distance of two points. We use these two points to form a circle, then quadrilateral and triangle must stay inside the circle, but they can still touch the boundary of the circle like cyclic quadrilateral and circumscribed circle. If we try any other orders, the sum of three shapes' area is not maximized because it violates the instruction 'One shape must wrap one shape'.<br /><br />
    To form a N-gon, we need at least N points. If the given N &lt; 2, we can simply print 0 as the answer. If not, we have to sort two arrays and get two multisets S1 and S2 in ascending order. Now, following the formation order, we compute the area of circle using two farthest points, that are, {S1<sub>0</sub>, S2<sub>0</sub>} and {S1<sub>N - 1</sub>, S2<sub>N - 1</sub>}. Now the number of remaining points CUR we can use is N - 2. The next step is to consider quadrilateral, which needs 4 points. If CUR equals 3, we skip the quadrilateral and compute the areae of triangle directly. If CUR &ge; 4, we use four extreme points in clockwise from lower left, that are {S1<sub>1</sub>, S2<sub>1</sub>}, {S1<sub>2</sub>, S2<sub>N - 3</sub>}, {S1<sub>N - 2</sub>, S2<sub>N - 2</sub>} and {S1<sub>N - 3</sub>, S2<sub>2</sub>} to form a 4-gon, and then CUR = CUR - 4.<br /><br />
    Now, the hardest part is to compute the area of triangle. Of course, we will only consider the four remaining extreme values of S1 and S2 respectively, two for smallest and two for largest (Or three values, depends on CUR). We create two empty multisets TX and TY, storing the candidate X and Y of vertices of resulting triangle. If the quadrilateral is skipped, TX = {S1<sub>1</sub>, S1<sub>2</sub>, S1<sub>3</sub>} and TY = {S2<sub>1</sub>, S2<sub>2</sub>, S2<sub>3</sub>}. If not, we set CUR = CUR - 4, and then if CUR &ge; 3, TX = {S1<sub>3</sub>, S1<sub>4</sub>} and TY = {S2<sub>3</sub>, S2<sub>4</sub>}. If CUR = 3, we insert S1<sub>5</sub> and S2<sub>5</sub> into TX and TY respectively. If CUR &gt; 3, we insert {S1<sub>N - 5</sub>, S1<sub>N - 4</sub>} and {S2<sub>N - 5</sub>, S2<sub>N - 4</sub>} into TX and TY respectively. Note that the size of TX is the same as the size of TY. As the order of coordinates will not affect the area of triangle, so we just have to find the combinations of any three points from the combinations of {TX, TY}. Firstly, we don't use the same point. Now, we can reduce the computation from SIZE<sub>TX</sub><sup>6</sup> times to 4<sup>2</sup> * 3<sup>2</sup> * 2<sup>2</sup> * 1<sup>2</sup> = 576 for SIZE<sub>TX</sub> = 4 or 3<sup>2</sup> * 2<sup>2</sup> * 1<sup>2</sup> = 36 for SIZE<sub>TX</sub> = 3, which is 36 times less. Secondly, the order is not important. Hence the iteration times can be further reduced to 96 and 6 for SIZE<sub>TX</sub> = 4 and SIZE<sub>TX</sub> = 3 respectively, also 36 times less. As for how to compute the area of N-gon by vertices, it is easy to find on the Internet, like using determinants for 3-gon and cross products for 4-gon. The whole problem can be solved in O(N * log N).
    </div>
    <div id="PRIPYAT">
    <div class="constraint">
      Problem statement: <a href="http://www.spoj.com/problems/PRIPYAT/" target="_blank">Link</a> | 
      Time: 9s per test file | 
      Source: 5000B | 
      Memory: 1536MB | 
      Languages: ALL
    </div>
    <hr />
    I wrote this problem to commemorate the 32-nd anniversary of the Chernobyl nuclear disaster, and my second visit to Chernobyl in May, 2018 since August, 2016. Okay, let's start the solution.
    <h3>Approach 1: Dynamic programming with bitmasking (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/PRIPYAT.cpp" target="_blank">Solution Link</a>)</h3>
    Firstly, we have to select some places to visit so that the total EXC is maximized and the VT and RL are less than or equal to the given limit. This is a classical 3D 0/1 knapsack problem, so we can use dynamic programming (DP). We define a function f1(x, y, z) as the maximum EXC we can get, in which we consider places from the first place to x-th place, by not exceeding y unit of VT and z amount of TL. Obviously, when any of x, y, z is 0, f1(x, y, z) is 0. For x &ge; 1, we only consider x-th place when VT<sub>x</sub> &le; y and RL<sub>x</sub> &le; z, hence we get f1(x, y, z) = max(f1(x - 1, y, z), f1(x - 1, y - VT<sub>x</sub>, z - RL<sub>x</sub>) + EXC<sub>x</sub>). Otherwise, it is impossible to accept VT<sub>x</sub>, RK<sub>x</sub>, or both, so we don't visit x-th place and f1(x, y, z) = f1(x - 1, y, z). Now, f1(N, MVT, TRL) is the maximum EXC we can get. We can know what places are selected by iterating over all f1's results backwards. Since the f1(x, y, z) is in increasing order, we start from f1(N, MVT, TRL), x-th place is selected when f1(x, y, z) &gt; f1(x - 1, y, z). After each selection, we set y to y - VT<sub>x</sub> and z to z - RL<sub>x</sub>. The iteration stops when any x, y, z is 0, which means it is impossible for all remaining places to meet all given limits. Note that RL is a set of real numbers with at most 2 digits after the decimal point, we can multiply RL and TRL by 100 so that the whole part can be solved by integer linear programming in O(N * MVT * TRL * 100).<br /><br />
    Now we know what places are selected, and have to find out the shortest distance from the starting point to visit all selected places without duplicate visit. The first step is to set all unselected places in the matrix to a barrier. Assume that K places are selected, as units are in equal distance, we will do a breadth first search (BFS) K + 1 times (because the starting point is included) at the location of i-th selected place to find out the shortest distance from i-th place to other places. Let the answer be DIST<sub>K, R, C</sub>. Note that when performing BFS, we must not put barriers and selected places into the queue (but we do calculate the shortest distance of that cell) because we are not allowed to visit the selected places twice or more. So, if the target is blocked, the distance will be INF (number larger than possible answer). This pre-calculation done in O(R * C * (K + 1)) gives us important information to optimize the result.<br /><br />
    Then, we can enumerate all possibilities with the help of DP and bitmasking. Integer can be represented by a set of bits which is either 1 or 0, which can be used in representing the state of a place. From the right, if the i-th bit is set, the i-th place is visited. Therefore, the bound of masks is 2<sup>K + 1</sup> - 1. We again define a function f2(x, y) as the shortest distance from x-th place to visit all the selected places by already visiting y in mask places. So, we only consider those places where haven't been to. From that, the DP state transition is as follows: for each place, if (y & (1 &lt;&lt; i)) is 0, f2(x, y) = min(f2(i, (y | (1 &lt;&lt; i))) + DIST<sub>x, R<sub>i</sub>, C<sub>i</sub></sub>). To avoid overlapping computation, in every recursion we can return the result immediately if f2(i, (y | (1 &lt;&lt; i)) is memoized already. Also, one possible sequence will stop calling f2 if all bits are set, which means all places are visited and equal to bound. We will start from the starting point and none of the place is visited except the starting point, so we initially call f2(0, 1). Remember that if one point is inaccessible from x-th place, the distance matrix of that cell is INF. It means that if the result obtained by f2(0, 1) &ge; INF, it is impossible to visit all selected places without duplicate visit from the starting point.<br /><br />
    With the help of DP and bitmasking, the time and space complexity is reduced, and the problem can still be solved accurately in reasonable time, which is O((K + 1) * (N * MVT * TRL * 100 + R * C + (K + 1)) * 2<sup>K + 1</sup>).
    </div>
    -->
      <div id="TRIBT">
        <div class="constraint">
          Problem statement: <a href="http://www.spoj.com/problems/TRIBT/" target="_blank">Link</a> | 
          Time: 1s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Tree</span><span class="tag">Depth-first Search</span>
        </div>
        <hr />
        The binary tree constructed from parent array may be either balanced, unbalanced, complete or full. We can count the number of potential isosceles triangles (PIT) by counting the number of edges connecting a node in some ways.
        <h3>Approach 1: Depth first search (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/TRIBT.cpp" target="_blank">Solution Link</a>)</h3>
        To meet the isosceles property, two sides of a trangle must have equal length. In a binary tree, we know that each node has at most two child and one parent, so the base of the PIT is either on the left, right or bottom, and at most two of them can be formed by a node at the same time. In any case, the vertex is always connected by existing edges in tree. Let's perform an in-order traversal using depth first search (DFS) from root and update our answer on the fly. <br /><br />
        Donate C<sub>i, [L, R]</sub> as the left(L) or right(R) child of i-th node, f(i, P<sub>L</sub>, P<sub>R</sub>) as a DFS function to calculate LC<sub>i</sub> and RC<sub>i</sub>, where LC<sub>i</sub> and RC<sub>i</sub> are the distance from i-th node to the leftmost leaf and rightmost leaf respectively. P<sub>L</sub> is the distance from i to the highest ancestor which is i's left predecessor, and P<sub>R</sub> the distance from i to the highest ancestor which is i's right predecessor. More simply, imagine you are at i-th node, you keep walking up until the direction changes (eg. The i-the node is its parent's left child, you walk up right and pass through the parent until a node is its parent's right child). If i is leaf, we reach the base case and the distance is 1. In the function, we treat i as the vertex of PIT and two edges with equal length join at i. For left child, since it will be the next vertex, and we can only produce the PIT with base on the right and bottom, hence L<sub>i</sub> = left of f(C<sub>i, L</sub>, P<sub>L</sub> + 1, 0). On the other hand, we can only produce the PIT with base on the left and bottom with right child as vertex, hence R<sub>i</sub> = right of f(C<sub>i, R</sub>, 0, P<sub>R</sub> + 1).<br /><br />
        So now we know the number of predecessors between i and its left or right highest ancestor, also the number of successors between i and its leftmost leaf and rightmost leaf. Due to the isosceles property, the number of nodes between any pair of sides must be equal, the maximum area of PIT is then determined by the minimum length of two sides, which can also be splited into M PITs, where M is the minimum length. Therefore, the answer of i-th node is min(LC<sub>i</sub>, RC<sub>i</sub>) + min(LC<sub>i</sub>, P<sub>R</sub>) + min(RC<sub>i</sub>, P<sub>L</sub>). We need to count the total number of PITs, so the formula should be applied to every node, which is &sum;<sub>i=1</sub><sup>N</sup>min(LC<sub>i</sub>, RC<sub>i</sub>) + min(LC<sub>i</sub>, P<sub>R</sub>) + min(RC<sub>i</sub>, P<sub>L</sub>), where N is the number of nodes in tree. The answer for each node is added up during the tree traversal by DFS recursively, that's why the problem is solved in O(N). I find the recursion implementation is much easier, can you solve it iteratively?
      </div>
      <div id="SMTOILET">
        <div class="constraint">
          Problem statement: <a href="http://www.spoj.com/problems/SMTOILET/" target="_blank">Link</a> | 
          Time: 0.45s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Prefix Sum</span><span class="tag">Basic Math</span><span class="tag">Binary Search</span><span class="tag">Simulation</span><span class="tag">Two pointers</span><span class="tag">Ad-hoc</span>
        </div>
        <hr />
        This is somehow an ad-hoc problem which doesn't require any prerequisite knowledge of algorithm and data structure, though we can still adopt some.
        <h3>Approach 1: Prefix sum and two pointers (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/SMTOILET_1.cpp" target="_blank">Solution Link</a>)</h3>
        Let T<sub>i</sub> be the amount of odors released by the i-th toilet, A<sub>i</sub> be the accumulative amount of odors at i-th second, S<sub>i</sub> be &sum;<sub>j=1</sub><sup>i</sup>T<sub>j</sub>. We know that A<sub>i</sub> is accumuated with the growth of time every second, therefore, A<sub>i</sub> = T<sub>1</sub> * i + T<sub>2</sub> * (i - 1) + ... + T<sub>i</sub>, which can be computed by prefix sum of S<sub>i</sub>. Once A &ge; M, the answer is either i or i + 1, since we are finding the answer with minimum difference between the answer and the amount of odors. If M is large enough, we can stand the accumulative smell of N toilets in N seconds, plus the extra amount of odors divided by S. The answer is either N + ((M - A<sub>N</sub>) / S<sub>N</sub>) + 1 or N + ((M - A<sub>N</sub>) / S<sub>N</sub>).<br /><br />
        As for the second part of the problem, given a string C, it can be solved by two pointers, which is basically to maintain two indexes to find out the longest portion of consecutive available cubicles. Let E be the entrance index, L, R be the leftmost and rightmost index of that portion. From that, we can calculate the length by i - L + R - i, and if the length is the longest, the optimal position is within the current portion. Note that the chosen position should be as middle in the portion as possible and as close to E as possible, if there are at least two portions with the same length, we can determine the best position based on the distance from i to E. Obviously we go to next next if C<sub>i</sub> = 'x' because that cubicle is already occupied.<br /><br />
        One optimization to this solution is to set i to R + 1 to avoid duplicated processing. However, this optimization requires us to deal with two cases: i &lt; E and i &gt; E if the length is even because we have two middles and it affects the distance to E. For i &lt; E we should choose the right position, otherwise left position. It requires more coding to handle the determination. Since |C| &le; 100 which is a small constraint, instead of an O(|C|) time complexity, I implemented an O(|C|<sup>2</sup>) solution to process the index one by one. Leave the faster solution as an exercise.
        <h3>Approach 2: Binary search and two pointers (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/SMTOILET_2.cpp" target="_blank">Solution Link</a>)</h3>
        As mentioned before, A is strictly increasing, we can use binary search. Let L and R be the lower bound and upper bound for binary search. We know that we need at least 1 second to wait for the release of odors, hence L = 1. For R, we can stand all amount of odors in first N seconds, plus extra amount of odors divided by S, hence R = N + (max(M - A<sub>N</sub>, 0) / S<sub>N</sub>) + 1. During each search, we use the median of L and R to validate the answer, hence MID = L + (H - L) / 2. We don't use (L + H) / 2 because of overflow. To check whether MID is a possible answer, we loop through T and calculate the accumulative sum by &sum;<sub>i=1</sub><sup>N</sup>T<sub>i</sub> * (MID - i - 1). If the return value V &lt; M, it means at MID seconds, the accumulative amount of odors is less than our tolerance, and we can stand more, so we set L to MID + 1. Otherwise, if V = M, it is probably our answer. If V &gt; M, it is definitly not a valid answer. Therefore, we set R to MID. Repeat the search until L &ge; R. Since we are finding the answer which minimizes the difference, and R is always &ge; M, either R or R - 1 will be the final answer. This part is done in O(N * log R).<br /><br />
        As for the second part of the problem, we use the same approach: Two pointers, so please refer to the second part of solution 1.
      </div>
      <div id="MAPEXC">
        <div class="constraint">
          Problem statement: <a href="http://www.spoj.com/problems/MAPEXC/" target="_blank">Link</a> | 
          Time: 0.6s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Graph</span><span class="tag">Breadth-first Search</span><span class="tag">Shortest Path</span>
        </div>
        <hr />
        Note that only moving from '.' to '.' will increase no cost, so we get two conditions for every move: 1. Cost remains unchanged, or 2. Cost increased by 1.Let's solve this problem as a single-source weighted shortest path problem in a grid, where the distance is either 0 or 1. One solution is to use Dijkstra's Algorithm, but we can simply use breadth first search (BFS).
        <h3>Approach 1: Breadth first search (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/MAPEXC_1.cpp" target="_blank">Solution Link</a>)</h3>
        Given a graph G, we have a source (Si, Sj) and a destination (Di, Dj). We are going to traverse G from (Si, Sj) in four directions (horizontally: j + 1, j - 1 and vertically: i + 1, i - 1). This can be done by BFS using a queue in O(N * M), where N is the row and M is the column of G respectively. We define C<sub>i, j</sub> as the minimum cost of exploring from (Si, Sj) to (i, j), initially set C<sub>Si, Sj</sub> to 0 and others to -1, because we are already there. From that, if C<sub>i, j</sub> = -1, we know that we haven't visited there yet. On each move, we check whether the adjacent cell (i2, j2) is within the boundary of G. If yes, we will update C<sub>i2, j2</sub> according to current value of C<sub>i2, j2</sub>, the map symbol of the current cell G<sub>i, j</sub> and that cell G<sub>i2, j2</sub>. With the following conditions, we update C<sub>i2, j2</sub> and put (i2, j2) into the queue if and only if we haven't visited there yet or we find a cheaper cost.
        <ul>
          <li>G<sub>i, j</sub> = '.' and G<sub>i2, j2</sub> = '.', and <br />
              C<sub>i2, j2</sub> = -1 or C<sub>i2, j2</sub> &gt; C<sub>i, j</sub>, then <br />
              C<sub>i2, j2</sub> = C<sub>i, j</sub> <br />
              This means we are moving from tunnel to tunnel, so no cost should be raised.
          </li>
          <li>G<sub>i, j</sub> &ne; '.' or G<sub>i2, j2</sub> &ne; '.', and <br />
              C<sub>i2, j2</sub> = -1 or C<sub>i2, j2</sub> &gt; C<sub>i, j</sub> + 1, then <br />
              C<sub>i2, j2</sub> = C<sub>i, j</sub> + 1 <br />
              This means we are either entering or leaving tunnel, so the cost is increased by 1.
          </li>
        </ul>
        Once the queue is empty, we have already travesed the whole graph and get C for every cell. To output the new map, we can simply print '.' if C<sub>i, j</sub> &le; C<sub>Di, Dj</sub>, otherwise print '#'. Don't forget to print the original cell if it is (Si, Sj) or (Di, Dj). We can also mix both depth first search (DFS) and BFS to solve this problem, the general idea is BFS - DFS - BFS. However it requires more coding and not applicable if G contains more than 1 tunnel. Leave it as an exercise.
      </div>
      <div id="TRFPLN">
        <div class="constraint">
          Problem statement: <a href="http://www.spoj.com/problems/TRFPLN/" target="_blank">Link</a> | 
          Time: 0.04s per test file | 
          Source: 5000B | 
          Memory: 1536MB | 
          Languages: ALL<br />
          Difficulty: 
          <i class="fa fa-star"></i>
          <i class="fa fa-star-half-o"></i>
          <i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><i class="fa fa-star-o"></i><br />
          <span class="tag">Greedy</span><span class="tag">Divide &amp; Conquer</span><span class="tag">Prefix Sum</span><span class="tag">Brute Force</span>
        </div>
        <hr />
        The grid pattern limits you to move horizontally or vertically, so we are required to calculate the 3D manhattan distance using formula |X<sub>i</sub> - X<sub>j</sub>| + |Y<sub>i</sub> - Y<sub>j</sub>| + |Z<sub>i</sub> - Z<sub>j</sub>|, between each pair of intersections, and the one with smallest sum of distances is the answer. An O(N<sup>2</sup>) brute force solution is likely to pass, but we can do better.
        <h3>Approach 1: Range sum of each dimension (<a href="https://github.com/him0727/Online-Judge-Solutions/blob/master/SPOJ/My_problems/TRFPLN.cpp" target="_blank">Solution Link</a>)</h3>
        For manhattan distance, we can consider each dimension independently. Let X', Y', Z' be the sorted points of each dimension from a list of coordinates in ascending order, each also records its original index of input list. Since they are sorted now, we can calculate the prefix sum for each dimension. For example, let S<sub>X, i</sub> be the prefix sum at i-th point of X', where S<sub>X, 0</sub> = 0, which is calculated as &sum;<sub>j=1</sub><sup>i</sup>X'<sub>j</sub>. From that, we can calculate the range sum of X' (i, j] by minusing the overlapping sum, hence S<sub>X, j</sub> - S<sub>X, i</sub> - (j - i) * X'<sub>i</sub>.<br /><br />
        Now let's consider the total distance [1, i] and (i, N] separately, where N is the total number of coordinates. For [1, i], we cannot directly use the range sum query because we want to compute the distance from i-th point, but the prefix sum is accumulated from 1-st point, therefore we use the formula i * X'<sub>i</sub> - S<sub>X, i</sub>. For (i, N], we can simply use the formula mentioned in previous paragraph, and the total distance from i-th point to all other points is the sum of two values. Let D<sub>X, i</sub> be the mapping of the total distance results and the original index of coordinates from the input list. Repeating the above steps for Y and Z to obtain D<sub>Y, i</sub> and D<sub>Z, i</sub>. Since the problem is about the manhattan distance, we can simply get the minimum total distance by finding the minimum of D<sub>X, i</sub> + D<sub>Y, i</sub> + D<sub>Z, i</sub> in O(N), where 1 &le; i &le; N, and return the coordinates with the minimum total distance. This solution requires sorting, so the overall time complexity is O(N * log N).
      </div>
    </div>
  </div>
  <hr />
  <footer></footer>
<script src="scripts/var.js"></script>
<script src="scripts/global.js"></script>
<script src="scripts/probs.js"></script>
</body>
</html>